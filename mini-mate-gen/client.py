import asyncio
import os
import json
from typing import Optional, Dict
from contextlib import AsyncExitStack

from openai import OpenAI
from dotenv import load_dotenv

from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client

load_dotenv()

class MultiServerMCPClient:
    def __init__(self):
        """ç®¡ç†å¤šä¸ª MCP æœåŠ¡å™¨çš„å®¢æˆ·ç«¯"""
        self.exit_stack = AsyncExitStack()
        self.openai_api_key = os.getenv("OPENAI_API_KEY")  
        self.base_url = os.getenv("BASE_URL")  
        self.model = os.getenv("MODEL")  
        if not self.openai_api_key:
            raise ValueError("âŒ æœªæ‰¾åˆ° OPENAI_API_KEYï¼Œè¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½®")

        # åˆå§‹åŒ– OpenAI Client
        self.client = OpenAI(api_key=self.openai_api_key, base_url=self.base_url)
        
        # å­˜å‚¨ (server_name -> MCP ClientSession) æ˜ å°„
        self.sessions: Dict[str, ClientSession] = {}
        # å­˜å‚¨å·¥å…·ä¿¡æ¯
        self.tools_by_session: Dict[str, list] = {}  # æ¯ä¸ª session çš„ tools åˆ—è¡¨
        self.all_tools = []  # åˆå¹¶æ‰€æœ‰å·¥å…·çš„åˆ—è¡¨

    async def connect_to_servers(self, servers: dict):
        """
        åŒæ—¶å¯åŠ¨å¤šä¸ªæœåŠ¡å™¨å¹¶è·å–å·¥å…·
        servers: å½¢å¦‚ {"weather": "weather_server.py", "rag": "rag_server.py"}
        """
        for server_name, script_path in servers.items():
            session = await self._start_one_server(script_path)
            self.sessions[server_name] = session
            
            # åˆ—å‡ºæ­¤æœåŠ¡å™¨çš„å·¥å…·
            resp = await session.list_tools()
            self.tools_by_session[server_name] = resp.tools  # ä¿å­˜åˆ° self.tools_by_session

            for tool in resp.tools:
                # OpenAI Function Calling æ ¼å¼ä¿®æ­£
                function_name = f"{server_name}_{tool.name}"
                # print(tool.name)
                self.all_tools.append({
                    "type": "function",
                    "function": {
                        "name": function_name,
                        "description": tool.description,
                        "input_schema": tool.inputSchema
                    }
                })
         
        
        # è½¬åŒ–function callingæ ¼å¼
        self.all_tools = await self.transform_json(self.all_tools)
        # print(self.all_tools)

        print("\nâœ… å·²è¿æ¥åˆ°ä¸‹åˆ—æœåŠ¡å™¨:")
        for name in servers:
            print(f"  - {name}: {servers[name]}")
        print("\næ±‡æ€»çš„å·¥å…·:")
        
        for t in self.all_tools:
            print(f"  - {t['function']['name']}")

    async def transform_json(self, json2_data):
        """
        å°†ç±»ä¼¼ json2 çš„æ ¼å¼è½¬æ¢ä¸ºç±»ä¼¼ json1 çš„æ ¼å¼ï¼Œå¤šä½™å­—æ®µä¼šè¢«ç›´æ¥åˆ é™¤ã€‚
        
        :param json2_data: ä¸€ä¸ªå¯è¢«è§£é‡Šä¸ºåˆ—è¡¨çš„ Python å¯¹è±¡ï¼ˆæˆ–å·²è§£æçš„ JSON æ•°æ®ï¼‰
        :return: è½¬æ¢åçš„æ–°åˆ—è¡¨
        """
        result = []
        
        for item in json2_data:
            # ç¡®ä¿æœ‰ "type" å’Œ "function" ä¸¤ä¸ªå…³é”®å­—æ®µ
            if not isinstance(item, dict) or "type" not in item or "function" not in item:
                continue
        
            old_func = item["function"]
        
            # ç¡®ä¿ function ä¸‹æœ‰æˆ‘ä»¬éœ€è¦çš„å…³é”®å­å­—æ®µ
            if not isinstance(old_func, dict) or "name" not in old_func or "description" not in old_func:
                continue
        
            # å¤„ç†æ–° function å­—æ®µ
            new_func = {
                "name": old_func["name"],
                "description": old_func["description"],
                "parameters": {}
            }
        
            # è¯»å– input_schema å¹¶è½¬æˆ parameters
            if "input_schema" in old_func and isinstance(old_func["input_schema"], dict):
                old_schema = old_func["input_schema"]
                
                # æ–°çš„ parameters ä¿ç•™ type, properties, required è¿™ä¸‰ä¸ªå­—æ®µ
                new_func["parameters"]["type"] = old_schema.get("type", "object")
                new_func["parameters"]["properties"] = old_schema.get("properties", {})
                new_func["parameters"]["required"] = old_schema.get("required", [])
            
            new_item = {
                "type": item["type"],
                "function": new_func
            }
        
            result.append(new_item)
    
        return result            

    async def _start_one_server(self, script_path: str) -> ClientSession:
        """å¯åŠ¨å•ä¸ª MCP æœåŠ¡å™¨å­è¿›ç¨‹ï¼Œå¹¶è¿”å› ClientSession"""
        is_python = script_path.endswith(".py")
        is_js = script_path.endswith(".js")
        if not (is_python or is_js):
            raise ValueError("æœåŠ¡å™¨è„šæœ¬å¿…é¡»æ˜¯ .py æˆ– .js æ–‡ä»¶")

        command = "python" if is_python else "node"
        server_params = StdioServerParameters(
            command=command,
            args=[script_path],
            env=None
        )
        stdio_transport = await self.exit_stack.enter_async_context(stdio_client(server_params))
        read_stream, write_stream = stdio_transport
        session = await self.exit_stack.enter_async_context(ClientSession(read_stream, write_stream))
        await session.initialize()
        return session


    async def chat_base(self, messages: list) -> list:
    
        # messages = [{"role": "user", "content": query}]
        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            tools=self.all_tools
        )
        if response.choices[0].finish_reason == "tool_calls":
            while True:
                messages = await self.create_function_response_messages(messages, response)
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=messages,
                    tools=self.all_tools
                )
                if response.choices[0].finish_reason != "tool_calls":
                    break
                    
        # return response.choices[0].message.content
        return response
        
    async def create_function_response_messages(self, messages, response):
        function_call_messages = response.choices[0].message.tool_calls
        messages.append(response.choices[0].message.model_dump())
        
        for function_call_message in function_call_messages:
            tool_name = function_call_message.function.name
            tool_args = json.loads(function_call_message.function.arguments)
        
            # è¿è¡Œå¤–éƒ¨å‡½æ•°
            function_response = await self._call_mcp_tool(tool_name, tool_args)

            # æ‹¼æ¥æ¶ˆæ¯é˜Ÿåˆ—
            messages.append(
                {
                    "role": "tool",
                    "content": function_response,
                    "tool_call_id": function_call_message.id,
                }
            )
        return messages  

    async def process_query(self, user_query: str) -> str:
        """
        OpenAI æœ€æ–° Function Calling é€»è¾‘:
         1. å‘é€ç”¨æˆ·æ¶ˆæ¯ + tools ä¿¡æ¯
         2. è‹¥æ¨¡å‹ `finish_reason == "tool_calls"`ï¼Œåˆ™è§£æ toolCalls å¹¶æ‰§è¡Œç›¸åº” MCP å·¥å…·
         3. æŠŠè°ƒç”¨ç»“æœè¿”å›ç»™ OpenAIï¼Œè®©æ¨¡å‹ç”Ÿæˆæœ€ç»ˆå›ç­”
        """
        messages = [{"role": "user", "content": user_query}]

        # ç¬¬ä¸€æ¬¡è¯·æ±‚
        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            tools=self.all_tools
        )
        content = response.choices[0]
        print(content)
        print(self.all_tools)

        # å¦‚æœæ¨¡å‹è°ƒç”¨äº† MCP å·¥å…·
        if content.finish_reason == "tool_calls":
            # è§£æ tool_calls
            tool_call = content.message.tool_calls[0]
            tool_name = tool_call.function.name  # å½¢å¦‚ "weather_query_weather"
            tool_args = json.loads(tool_call.function.arguments)

            print(f"\n[ è°ƒç”¨å·¥å…·: {tool_name}, å‚æ•°: {tool_args} ]\n")

            # æ‰§è¡ŒMCPå·¥å…·
            result = await self._call_mcp_tool(tool_name, tool_args)

            # æŠŠå·¥å…·è°ƒç”¨å†å²å†™è¿› messages
            messages.append(content.message.model_dump())
            messages.append({
                "role": "tool",
                "content": result,
                "tool_call_id": tool_call.id,
            })
            # ç¬¬äºŒæ¬¡è¯·æ±‚ï¼Œè®©æ¨¡å‹æ•´åˆå·¥å…·ç»“æœï¼Œç”Ÿæˆæœ€ç»ˆå›ç­”
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages
            )
            return response.choices[0].message.content

        # å¦‚æœæ¨¡å‹æ²¡è°ƒç”¨å·¥å…·ï¼Œç›´æ¥è¿”å›å›ç­”
        return content.message.content

    async def _call_mcp_tool(self, tool_full_name: str, tool_args: dict) -> str:
        """
        æ ¹æ® "serverName_toolName" è°ƒç”¨ç›¸åº”çš„æœåŠ¡å™¨å·¥å…·
        """
        parts = tool_full_name.split("_", 1)  # æ‹†åˆ† "weather_query_weather" -> ["weather", "query_weather"]
        if len(parts) != 2:
            return f"æ— æ•ˆçš„å·¥å…·åç§°: {tool_full_name}"

        server_name, tool_name = parts
        session = self.sessions.get(server_name)
        if not session:
            return f"æ‰¾ä¸åˆ°æœåŠ¡å™¨: {server_name}"
        
        # æ‰§è¡Œ MCP å·¥å…·
        resp = await session.call_tool(tool_name, tool_args)
        print(resp)
        return resp.content[0].text if resp.content else "å·¥å…·æ‰§è¡Œæ— è¾“å‡º"

    async def chat_loop(self):
        print("\nğŸ¤– å¤šæœåŠ¡å™¨ MCP + æœ€æ–° Function Calling å®¢æˆ·ç«¯å·²å¯åŠ¨ï¼è¾“å…¥ 'quit' é€€å‡ºã€‚")
        messages = []

        while True:
            query = input("\nä½ : ").strip()
            if query.lower() == "quit":
                break
            try:
                messages.append({"role": "user", "content": query})
                messages = messages[-20: ]
                # print(messages)
                response = await self.chat_base(messages)
                messages.append(response.choices[0].message.model_dump())
                result = response.choices[0].message.content
                
                print(f"\nAI: {result}")
            except Exception as e:
                print(f"\nâš ï¸  è°ƒç”¨è¿‡ç¨‹å‡ºé”™: {e}")

    async def cleanup(self):
        # å…³é—­æ‰€æœ‰èµ„æº
        await self.exit_stack.aclose()

async def main():
    # æœåŠ¡å™¨è„šæœ¬
    servers = {
        # "write": "write_server.py",
        "weather": "weather-server.py",
        "SQLServer":"sql-server.py",
        "PythonServer":"python-server.py"
    }

    client = MultiServerMCPClient()
    try:
        await client.connect_to_servers(servers)
        await client.chat_loop()
    finally:
        await client.cleanup()

if __name__ == "__main__":
    asyncio.run(main())
