import asyncio
import os
import json
from typing import Optional
from contextlib import AsyncExitStack

from openai import OpenAI  
from dotenv import load_dotenv

from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client

# åŠ è½½ .env æ–‡ä»¶ï¼Œç¡®ä¿ API Key å—åˆ°ä¿æŠ¤
load_dotenv()

class MCPClient:
    def __init__(self):
        """åˆå§‹åŒ– MCP å®¢æˆ·ç«¯"""
        self.exit_stack = AsyncExitStack() # ç”¨äºŽ ç»Ÿä¸€ç®¡ç†å¼‚æ­¥ä¸Šä¸‹æ–‡ï¼ˆå¦‚ MCP è¿žæŽ¥ï¼‰çš„ç”Ÿå‘½å‘¨æœŸã€‚- å¯ä»¥åœ¨é€€å‡ºï¼ˆcleanupï¼‰æ—¶è‡ªåŠ¨å…³é—­ã€‚
        self.openai_api_key = os.getenv("OPENAI_API_KEY")  # è¯»å– OpenAI API Key
        self.base_url = os.getenv("BASE_URL")  # è¯»å– BASE YRL
        self.model = os.getenv("MODEL")  # è¯»å– model
        if not self.openai_api_key:
            raise ValueError("âŒ æœªæ‰¾åˆ° OpenAI API Keyï¼Œè¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® OPENAI_API_KEY")
        self.client = OpenAI(api_key=self.openai_api_key, base_url=self.base_url) # åˆ›å»ºOpenAI client
        self.session: Optional[ClientSession] = None # ç”¨äºŽä¿å­˜ MCP çš„å®¢æˆ·ç«¯ä¼šè¯ï¼Œé»˜è®¤æ˜¯ Noneï¼Œç¨åŽé€šè¿‡ connect_to_server è¿›è¡Œè¿žæŽ¥
        self.exit_stack = AsyncExitStack() # è¿™é‡Œä¸¤æ¬¡èµ‹å€¼å…¶å®žæœ‰ç‚¹å†—ä½™ï¼ˆå‰é¢å·²èµ‹å€¼è¿‡ä¸€æ¬¡ï¼‰ã€‚ä¸è¿‡å¹¶ä¸å½±å“åŠŸèƒ½ï¼Œç­‰åŒäºŽè¦†ç›–æŽ‰å‰é¢çš„å¯¹è±¡ã€‚å¯èƒ½æ˜¯æ‰‹è¯¯æˆ–è°ƒè¯•æ—¶å¤šå†™äº†ä¸€æ¬¡

    async def connect_to_server(self, server_script_path: str):
        """è¿žæŽ¥åˆ° MCP æœåŠ¡å™¨å¹¶åˆ—å‡ºå¯ç”¨å·¥å…·"""
        is_python = server_script_path.endswith('.py')
        is_js = server_script_path.endswith('.js')
        if not (is_python or is_js):
            raise ValueError("æœåŠ¡å™¨è„šæœ¬å¿…é¡»æ˜¯ .py æˆ– .js æ–‡ä»¶")

        command = "python" if is_python else "node"
        server_params = StdioServerParameters(
            command=command,
            args=[server_script_path],
            env=None
        )

        # å¯åŠ¨ MCP æœåŠ¡å™¨å¹¶å»ºç«‹é€šä¿¡
        stdio_transport = await self.exit_stack.enter_async_context(stdio_client(server_params)) # å¯åŠ¨æœåŠ¡å™¨è¿›ç¨‹ï¼Œå¹¶å»ºç«‹ æ ‡å‡† I/O é€šä¿¡ç®¡é“ã€‚
        self.stdio, self.write = stdio_transport #æ‹¿åˆ°è¯»å†™æµ
        self.session = await self.exit_stack.enter_async_context(ClientSession(self.stdio, self.write)) # åˆ›å»º MCP å®¢æˆ·ç«¯ä¼šè¯ï¼Œä¸ŽæœåŠ¡å™¨äº¤äº’

        await self.session.initialize() # å‘é€åˆå§‹åŒ–æ¶ˆæ¯ç»™æœåŠ¡å™¨ï¼Œç­‰å¾…æœåŠ¡å™¨å°±ç»ª

        # åˆ—å‡º MCP æœåŠ¡å™¨ä¸Šçš„å·¥å…·
        response = await self.session.list_tools()
        tools = response.tools
        print("\nå·²è¿žæŽ¥åˆ°æœåŠ¡å™¨ï¼Œæ”¯æŒä»¥ä¸‹å·¥å…·:", [tool.name for tool in tools])     

    # ä¸ºä»€ä¹ˆè¦ä¸¤æ¬¡è¯·æ±‚ï¼Ÿ
    #   - ç¬¬ä¸€æ¬¡ï¼šæ¨¡åž‹æ ¹æ®ä½ çš„æŒ‡ä»¤ï¼Œå†³å®šè¦ä¸è¦ç”¨å·¥å…·
    #   - å¦‚æžœéœ€è¦ç”¨å·¥å…· â†’ è¿”å›žå·¥å…·åç§°å’Œå‚æ•° â†’ æ‰§è¡Œå·¥å…· â†’ æŠŠç»“æžœä½œä¸ºæ–°çš„ä¸Šä¸‹æ–‡å‘ç»™æ¨¡åž‹
    #   - ç¬¬äºŒæ¬¡ï¼šæ¨¡åž‹åŸºäºŽå·¥å…·ç»“æžœç»™å‡ºæœ€ç»ˆå›žç­”
    async def process_query(self, query: str) -> str:
        """
        ä½¿ç”¨å¤§æ¨¡åž‹å¤„ç†æŸ¥è¯¢å¹¶è°ƒç”¨å¯ç”¨çš„ MCP å·¥å…· (Function Calling)
        """
        messages = [{"role": "user", "content": query}]
        
        response = await self.session.list_tools()
        
        available_tools = [{
            "type": "function",
            "function": {
                "name": tool.name,
                "description": tool.description,
                "input_schema": tool.inputSchema
            }
        } for tool in response.tools]
        # print(available_tools)

        # ä½¿ç”¨ OpenAI å®¢æˆ·ç«¯çš„æ–¹æ³•å‘é€è¯·æ±‚
        response = self.client.chat.completions.create(
            model=self.model,            
            messages=messages,
            tools=available_tools     
        )
        
        # å¤„ç†è¿”å›žçš„å†…å®¹
        content = response.choices[0]
        if content.finish_reason == "tool_calls":
            # å¦‚ä½•æ˜¯éœ€è¦ä½¿ç”¨å·¥å…·ï¼Œå°±è§£æžå·¥å…·
            messages.append(content.message.model_dump())
            for tool_call in content.message.tool_calls:
                tool_name = tool_call.function.name
                tool_args = json.loads(tool_call.function.arguments)
                # æ‰§è¡Œå·¥å…·
                result = await self.session.call_tool(tool_name, tool_args)
                print(f"\n\n[Calling tool {tool_name} with args {tool_args}]\n\n")

                # å°†æ¨¡åž‹è¿”å›žçš„è°ƒç”¨å“ªä¸ªå·¥å…·æ•°æ®å’Œå·¥å…·æ‰§è¡Œå®ŒæˆåŽçš„æ•°æ®éƒ½å­˜å…¥messagesä¸­
                messages.append({
                    "role": "tool",
                    "content": result.content[0].text,
                    "tool_call_id": tool_call.id,
                })
            # å°†ä¸Šé¢çš„ç»“æžœå†è¿”å›žç»™å¤§æ¨¡åž‹ç”¨äºŽç”Ÿäº§æœ€ç»ˆçš„ç»“æžœ
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
            )
            return response.choices[0].message.content
        # å¦‚æžœæ²¡æœ‰è¦è°ƒç”¨å·¥å…·ï¼Œç›´æŽ¥è¿”å›ž content.message.contentï¼ˆæ¨¡åž‹çš„æ–‡æœ¬å›žç­”ï¼‰
        return content.message.content
    
    async def chat_loop(self):
        """è¿è¡Œäº¤äº’å¼èŠå¤©å¾ªçŽ¯"""
        print("\nðŸ¤– MCP å®¢æˆ·ç«¯å·²å¯åŠ¨ï¼è¾“å…¥ 'quit' é€€å‡º")

        while True:
            try:
                query = input("\nä½ : ").strip()
                if query.lower() == 'quit':
                    break
                
                response = await self.process_query(query)  # å‘é€ç”¨æˆ·è¾“å…¥åˆ° OpenAI API
                print(f"\nðŸ¤– DeepSeekAI: {response}")

            except Exception as e:
                print(f"\nâš ï¸ å‘ç”Ÿé”™è¯¯: {str(e)}")

    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        await self.exit_stack.aclose() # å¼‚æ­¥åœ°å…³é—­æ‰€æœ‰åœ¨ exit_stack ä¸­æ³¨å†Œçš„èµ„æºï¼ˆåŒ…æ‹¬ MCP ä¼šè¯ï¼‰

async def main():
    server_script_path = sys.argv[1] if len(sys.argv) >= 2 else os.path.join(os.path.dirname(__file__), "server.py")
    client = MCPClient()
    try:
        await client.connect_to_server(server_script_path)
        await client.chat_loop()
    finally:
        await client.cleanup()

if __name__ == "__main__":
    import sys
    asyncio.run(main())
